{"model_name_or_path": "250522_anthropic_filemap_simple_review__claude-sonnet-4-20250514__t-0.00__p-1.00__c-3.00___swe_bench_verified_test", "instance_id": "scikit-learn__scikit-learn-25102", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..df1b53cce 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -154,7 +154,7 @@ class Pipeline(_BaseComposition):\n         self.memory = memory\n         self.verbose = verbose\n \n-    def set_output(self, *, transform=None):\n+    def set_output(self, *, transform=None, dtypes=None):\n         \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n         Calling `set_output` will set the output of all estimators in `steps`.\n@@ -168,13 +168,19 @@ class Pipeline(_BaseComposition):\n             - `\"pandas\"`: DataFrame output\n             - `None`: Transform configuration is unchanged\n \n+        dtypes : {\"preserve\"}, default=None\n+            Configure whether to preserve dtypes when using pandas output.\n+\n+            - `\"preserve\"`: Preserve the dtypes of the input DataFrame\n+            - `None`: Dtypes configuration is unchanged\n+\n         Returns\n         -------\n         self : estimator instance\n             Estimator instance.\n         \"\"\"\n         for _, _, step in self._iter():\n-            _safe_set_output(step, transform=transform)\n+            _safe_set_output(step, transform=transform, dtypes=dtypes)\n         return self\n \n     def get_params(self, deep=True):\n@@ -1027,7 +1033,7 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         self.transformer_weights = transformer_weights\n         self.verbose = verbose\n \n-    def set_output(self, *, transform=None):\n+    def set_output(self, *, transform=None, dtypes=None):\n         \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n         `set_output` will set the output of all estimators in `transformer_list`.\n@@ -1041,14 +1047,20 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n             - `\"pandas\"`: DataFrame output\n             - `None`: Transform configuration is unchanged\n \n+        dtypes : {\"preserve\"}, default=None\n+            Configure whether to preserve dtypes when using pandas output.\n+\n+            - `\"preserve\"`: Preserve the dtypes of the input DataFrame\n+            - `None`: Dtypes configuration is unchanged\n+\n         Returns\n         -------\n         self : estimator instance\n             Estimator instance.\n         \"\"\"\n-        super().set_output(transform=transform)\n+        super().set_output(transform=transform, dtypes=dtypes)\n         for _, step, _ in self._iter():\n-            _safe_set_output(step, transform=transform)\n+            _safe_set_output(step, transform=transform, dtypes=dtypes)\n         return self\n \n     @property\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..2abd06eaf 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -12,6 +12,7 @@ def _wrap_in_pandas_container(\n     *,\n     columns,\n     index=None,\n+    dtypes=None,\n ):\n     \"\"\"Create a Pandas DataFrame.\n \n@@ -36,6 +37,10 @@ def _wrap_in_pandas_container(\n     index : array-like, default=None\n         Index for data.\n \n+    dtypes : pandas.Series, dict, or None, default=None\n+        The dtypes to apply to the output DataFrame. If provided, the output\n+        DataFrame will be cast to these dtypes using `astype`.\n+\n     Returns\n     -------\n     dataframe : DataFrame\n@@ -57,9 +62,36 @@ def _wrap_in_pandas_container(\n             data_to_wrap.columns = columns\n         if index is not None:\n             data_to_wrap.index = index\n+        # Apply dtypes if provided\n+        if dtypes is not None:\n+            # Only apply dtypes for columns that exist in both dtypes and the DataFrame\n+            if hasattr(dtypes, 'index'):  # pandas Series\n+                common_cols = data_to_wrap.columns.intersection(dtypes.index)\n+                if len(common_cols) > 0:\n+                    data_to_wrap = data_to_wrap.astype(dtypes[common_cols])\n+            elif isinstance(dtypes, dict):\n+                common_cols = set(data_to_wrap.columns).intersection(set(dtypes.keys()))\n+                if len(common_cols) > 0:\n+                    dtype_subset = {col: dtypes[col] for col in common_cols}\n+                    data_to_wrap = data_to_wrap.astype(dtype_subset)\n         return data_to_wrap\n \n-    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n+    df = pd.DataFrame(data_to_wrap, index=index, columns=columns)\n+    \n+    # Apply dtypes if provided\n+    if dtypes is not None:\n+        # Only apply dtypes for columns that exist in both dtypes and the DataFrame\n+        if hasattr(dtypes, 'index'):  # pandas Series\n+            common_cols = df.columns.intersection(dtypes.index)\n+            if len(common_cols) > 0:\n+                df = df.astype(dtypes[common_cols])\n+        elif isinstance(dtypes, dict):\n+            common_cols = set(df.columns).intersection(set(dtypes.keys()))\n+            if len(common_cols) > 0:\n+                dtype_subset = {col: dtypes[col] for col in common_cols}\n+                df = df.astype(dtype_subset)\n+    \n+    return df\n \n \n def _get_output_config(method, estimator=None):\n@@ -81,6 +113,8 @@ def _get_output_config(method, estimator=None):\n \n         - \"dense\": specifies the dense container for `method`. This can be\n           `\"default\"` or `\"pandas\"`.\n+        - \"dtypes\": specifies whether to preserve dtypes. This can be\n+          `\"preserve\"` or `None`.\n     \"\"\"\n     est_sklearn_output_config = getattr(estimator, \"_sklearn_output_config\", {})\n     if method in est_sklearn_output_config:\n@@ -93,7 +127,19 @@ def _get_output_config(method, estimator=None):\n             f\"output config must be 'default' or 'pandas' got {dense_config}\"\n         )\n \n-    return {\"dense\": dense_config}\n+    # Get dtypes config\n+    dtypes_key = f\"{method}_dtypes\"\n+    if dtypes_key in est_sklearn_output_config:\n+        dtypes_config = est_sklearn_output_config[dtypes_key]\n+    else:\n+        dtypes_config = None\n+\n+    if dtypes_config is not None and dtypes_config not in {\"preserve\"}:\n+        raise ValueError(\n+            f\"dtypes config must be 'preserve' or None, got {dtypes_config}\"\n+        )\n+\n+    return {\"dense\": dense_config, \"dtypes\": dtypes_config}\n \n \n def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n@@ -127,10 +173,16 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n         return data_to_wrap\n \n     # dense_config == \"pandas\"\n+    # Prepare dtypes if preservation is requested\n+    dtypes = None\n+    if output_config[\"dtypes\"] == \"preserve\" and hasattr(original_input, \"dtypes\"):\n+        dtypes = original_input.dtypes\n+    \n     return _wrap_in_pandas_container(\n         data_to_wrap=data_to_wrap,\n         index=getattr(original_input, \"index\", None),\n         columns=estimator.get_feature_names_out,\n+        dtypes=dtypes,\n     )\n \n \n@@ -208,7 +260,7 @@ class _SetOutputMixin:\n             setattr(cls, method, wrapped_method)\n \n     @available_if(_auto_wrap_is_configured)\n-    def set_output(self, *, transform=None):\n+    def set_output(self, *, transform=None, dtypes=None):\n         \"\"\"Set output container.\n \n         See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n@@ -223,22 +275,35 @@ class _SetOutputMixin:\n             - `\"pandas\"`: DataFrame output\n             - `None`: Transform configuration is unchanged\n \n+        dtypes : {\"preserve\"}, default=None\n+            Configure whether to preserve dtypes when using pandas output.\n+\n+            - `\"preserve\"`: Preserve the dtypes of the input DataFrame\n+            - `None`: Dtypes configuration is unchanged\n+\n         Returns\n         -------\n         self : estimator instance\n             Estimator instance.\n         \"\"\"\n-        if transform is None:\n+        if transform is None and dtypes is None:\n             return self\n \n         if not hasattr(self, \"_sklearn_output_config\"):\n             self._sklearn_output_config = {}\n \n-        self._sklearn_output_config[\"transform\"] = transform\n+        if transform is not None:\n+            self._sklearn_output_config[\"transform\"] = transform\n+        if dtypes is not None:\n+            if dtypes not in {\"preserve\"}:\n+                raise ValueError(\n+                    f\"dtypes must be 'preserve' or None, got {dtypes}\"\n+                )\n+            self._sklearn_output_config[\"transform_dtypes\"] = dtypes\n         return self\n \n \n-def _safe_set_output(estimator, *, transform=None):\n+def _safe_set_output(estimator, *, transform=None, dtypes=None):\n     \"\"\"Safely call estimator.set_output and error if it not available.\n \n     This is used by meta-estimators to set the output for child estimators.\n@@ -256,6 +321,12 @@ def _safe_set_output(estimator, *, transform=None):\n \n         If `None`, this operation is a no-op.\n \n+    dtypes : {\"preserve\"}, default=None\n+        Configure whether to preserve dtypes when using pandas output.\n+\n+        - `\"preserve\"`: Preserve the dtypes of the input DataFrame\n+        - `None`: Dtypes configuration is unchanged\n+\n     Returns\n     -------\n     estimator : estimator instance\n@@ -264,7 +335,7 @@ def _safe_set_output(estimator, *, transform=None):\n     set_output_for_transform = (\n         hasattr(estimator, \"transform\")\n         or hasattr(estimator, \"fit_transform\")\n-        and transform is not None\n+        and (transform is not None or dtypes is not None)\n     )\n     if not set_output_for_transform:\n         # If estimator can not transform, then `set_output` does not need to be\n@@ -276,4 +347,12 @@ def _safe_set_output(estimator, *, transform=None):\n             f\"Unable to configure output for {estimator} because `set_output` \"\n             \"is not available.\"\n         )\n-    return estimator.set_output(transform=transform)\n+    \n+    # Check if the estimator's set_output method supports dtypes parameter\n+    import inspect\n+    sig = inspect.signature(estimator.set_output)\n+    if 'dtypes' in sig.parameters:\n+        return estimator.set_output(transform=transform, dtypes=dtypes)\n+    else:\n+        # Fallback for estimators that don't support dtypes parameter yet\n+        return estimator.set_output(transform=transform)\n"}